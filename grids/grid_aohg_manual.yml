n_hidden_channels: [1024]
n_linear_layers: [2]
n_graph_layers: [5]
p_linear_dropout: [0.2]
p_graph_dropout: [0.2]
lr: [1.e-3]
weight_decay: [1.0e-10]
batch_size: [256]
one_hot_mode: [none] #, ffn, conv
one_hot_attention: [uoi, dot]
one_hot_incay: [add, binary, binary_add]
use_normal_attention: [False, True]
add_self_loops: [True, False]
one_hot_att_constant: [1., 0.1, 5]