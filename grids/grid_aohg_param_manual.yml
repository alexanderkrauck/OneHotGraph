n_hidden_channels: [1024]
n_linear_layers: [2]
n_graph_layers: [5]
p_linear_dropout: [0.2]
p_graph_dropout: [0.2]
lr: [1.e-3]
weight_decay: [1.0e-10]
batch_size: [256]
one_hot_mode: [none] #, ffn, conv
one_hot_attention: [dot]
one_hot_incay: [add]
use_normal_attention: [True]
add_self_loops: [True]
one_hot_att_constant: [0.1]
heads: [8]
train_one_hot_att_constant: [True, False]